{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e8e857-b05e-4fb7-83ad-0527e669c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e7022d-4b77-4985-a914-7a697093d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station: USC00305800\n",
      "Location: {'latitude': 40.7789, 'longitude': -73.9692}\n",
      "First observation: {'date': '2023-01-01', 'temperature': 32, 'precipitation': 0.0}\n"
     ]
    }
   ],
   "source": [
    "sample_json = '''\n",
    "{\n",
    "  \"station\": \"USC00305800\",\n",
    "  \"name\": \"New York Central Park\",\n",
    "  \"location\": {\n",
    "    \"latitude\": 40.7789,\n",
    "    \"longitude\": -73.9692\n",
    "  },\n",
    "  \"observations\": [\n",
    "    {\"date\": \"2023-01-01\", \"temperature\": 32, \"precipitation\": 0.0},\n",
    "    {\"date\": \"2023-01-02\", \"temperature\": 28, \"precipitation\": 0.5},\n",
    "    {\"date\": \"2023-01-03\", \"temperature\": 35, \"precipitation\": 0.0},\n",
    "    {\"date\": \"2023-01-04\", \"temperature\": 38, \"precipitation\": 0.2},\n",
    "    {\"date\": \"2023-01-05\", \"temperature\": 41, \"precipitation\": 0.0}\n",
    "  ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse the JSON\n",
    "data = json.loads(sample_json)\n",
    "\n",
    "# Access nested data\n",
    "print(\"Station:\", data['station'])\n",
    "print(\"Location:\", data['location'])\n",
    "print(\"First observation:\", data['observations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb96792-fad6-498a-a2f5-ca9c9f212157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date, Temperature\n",
      "2023-01-01 32\n",
      "2023-01-02 28\n",
      "2023-01-03 35\n",
      "2023-01-04 38\n",
      "2023-01-05 41\n",
      "Average temperature: 34.8°F\n",
      "\n",
      "Days with precipitation:\n",
      "2023-01-02 0.5\n",
      "2023-01-04 0.2\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract and print all dates and temperatures (8 points)\n",
    "print(\"Date, Temperature\")\n",
    "for obs in data['observations']:\n",
    "    print(obs['date'], obs['temperature'])\n",
    "\n",
    "# 2. Calculate average temperature (8 points)\n",
    "total_temp = 0\n",
    "count = 0\n",
    "\n",
    "for obs in data['observations']:\n",
    "    total_temp += obs['temperature']\n",
    "    count += 1\n",
    "\n",
    "avg_temp = total_temp / count\n",
    "print(f\"Average temperature: {avg_temp}°F\")\n",
    "# 3. Find days with precipitation (9 points)\n",
    "print(\"\\nDays with precipitation:\")\n",
    "for obs in data['observations']:\n",
    "    if obs['precipitation'] > 0:\n",
    "        print(obs['date'], obs['precipitation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4eeb032-3f7a-4fcd-8697-ea14010cc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: /home/tao2133/.cache/pooch/458dad453f6a48e510cd544bef1854e3-air_quality_no2.csv\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "import pooch\n",
    "\n",
    "# Set up Pooch to download a file\n",
    "# This example downloads a small air quality dataset\n",
    "file_path = pooch.retrieve(\n",
    "    url=\"https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_no2.csv\",\n",
    "    known_hash=None\n",
    ")\n",
    "\n",
    "print(\"File downloaded to:\", file_path)\n",
    "print(\"File exists:\", os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e76c2b36-93a4-40aa-8d61-add340e2baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 31984 bytes\n",
      "Number of lines: 1035\n",
      "             name     id nametype              recclass  mass (g)   fall  \\\n",
      "0          Aachen      1    Valid                    L5      21.0   Fell   \n",
      "1          Aarhus      2    Valid                    H6     720.0   Fell   \n",
      "2            Abee      6    Valid                   EH4  107000.0   Fell   \n",
      "3        Acapulco     10    Valid           Acapulcoite    1914.0   Fell   \n",
      "4         Achiras    370    Valid                    L6     780.0   Fell   \n",
      "...           ...    ...      ...                   ...       ...    ...   \n",
      "45711  Zillah 002  31356    Valid               Eucrite     172.0  Found   \n",
      "45712      Zinder  30409    Valid  Pallasite, ungrouped      46.0  Found   \n",
      "45713        Zlin  30410    Valid                    H4       3.3  Found   \n",
      "45714   Zubkovsky  31357    Valid                    L6    2167.0  Found   \n",
      "45715  Zulu Queen  30414    Valid                  L3.7     200.0  Found   \n",
      "\n",
      "         year    reclat    reclong             GeoLocation  \n",
      "0      1880.0  50.77500    6.08333       (50.775, 6.08333)  \n",
      "1      1951.0  56.18333   10.23333    (56.18333, 10.23333)  \n",
      "2      1952.0  54.21667 -113.00000      (54.21667, -113.0)  \n",
      "3      1976.0  16.88333  -99.90000       (16.88333, -99.9)  \n",
      "4      1902.0 -33.16667  -64.95000     (-33.16667, -64.95)  \n",
      "...       ...       ...        ...                     ...  \n",
      "45711  1990.0  29.03700   17.01850       (29.037, 17.0185)  \n",
      "45712  1999.0  13.78333    8.96667     (13.78333, 8.96667)  \n",
      "45713  1939.0  49.25000   17.66667       (49.25, 17.66667)  \n",
      "45714  2003.0  49.78917   41.50460     (49.78917, 41.5046)  \n",
      "45715  1976.0  33.98333 -115.68333  (33.98333, -115.68333)  \n",
      "\n",
      "[45716 rows x 10 columns]\n",
      "\n",
      "Data Inventory:\n",
      "1. meteorites.csv - NASA meteorite landings\n",
      "2. air_quality_no2.csv - Air quality NO2 measurements\n",
      "3. Meteorite_Landings.csv - NASA meteorite landings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Verify the file was downloaded (5 points)\n",
    "# Check the file size\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f\"File size: {file_size} bytes\")\n",
    "\n",
    "# YOUR CODE HERE: open the file and count how many lines it has\n",
    "line_count = 0 \n",
    "read_file = pd.read_csv(\"/home/tao2133/.cache/pooch/458dad453f6a48e510cd544bef1854e3-air_quality_no2.csv\")\n",
    "\n",
    "for i in read_file.index:\n",
    "    line_count+= 1\n",
    "\n",
    "print(f\"Number of lines: {line_count}\")\n",
    "\n",
    "# 2. Download another file (10 points)\n",
    "# Find a climate dataset online using the sources we talked about in lecture\n",
    "# Download it using Pooch\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "my_url = \"https://data.nasa.gov/docs/legacy/meteorite_landings/Meteorite_Landings.csv\"\n",
    "my_file = pooch.retrieve(url=my_url, known_hash=None)  # hash optional for first try\n",
    "print(pd.read_csv(\"/home/tao2133/.cache/pooch/a19fd2df36fd8edbdc8806f06d01424b-Meteorite_Landings.csv\"))\n",
    "#Print info about your downloaded file\n",
    "\n",
    "# 3. Create a data inventory (5 points)\n",
    "# List all the files you've downloaded in this assignment\n",
    "print(\"\\nData Inventory:\")\n",
    "print(\"1. meteorites.csv - NASA meteorite landings\")\n",
    "print(\"2. air_quality_no2.csv - Air quality NO2 measurements\")\n",
    "print(\"3. Meteorite_Landings.csv - NASA meteorite landings\")\n",
    "# YOUR CODE HERE: add your file from task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1c0c090-2b74-494c-8973-8692d7e690bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "Dataset {\n",
      "    Float32 T[T = 324];\n",
      "    Float32 Y[Y = 360];\n",
      "    Float32 X[X = 720];\n",
      "    Grid {\n",
      "     ARRAY:\n",
      "        Float32 rain[T = 324][Y = 360][X = 720];\n",
      "     MAPS:\n",
      "        Float32 T[T = 324];\n",
      "        Float32 Y[Y = 360];\n",
      "        Float32 X[X = 720];\n",
      "    } rain;\n",
      "} rain;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# OPeNDAP provides metadata in different formats\n",
    "# We'll get basic info about a climate dataset\n",
    "\n",
    "base_url = \"http://iridl.ldeo.columbia.edu/expert/SOURCES/.NOAA/.NCEP/.CPC/.UNIFIED_PRCP/.GAUGE_BASED/.GLOBAL/.v1p0/.Monthly/.RETRO/.rain/dods\"\n",
    "\n",
    "# Get DDS (Dataset Descriptor Structure) - describes the structure\n",
    "dds_url = base_url + \".dds\"\n",
    "response = requests.get(dds_url)\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "print(response.text[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881bda5-633c-49b5-9260-58ab61be27c1",
   "metadata": {},
   "source": [
    "# 1. Identify dimensions and variables (5 points)\n",
    "# Look at the DDS output above and answer:\n",
    "# - What are the dimension names?\n",
    "# - What is the main variable name?\n",
    "# - Write your answers in a markdown cell\n",
    "\n",
    "### Dimensions and Variables\n",
    "\n",
    "- **Dimension names:** T (time), Y (latitude), X (longitude)\n",
    "- **Main variable:** rain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35bccf16-4d67-444f-bbf9-4496aa041c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Attributes:\n",
      "Attributes {\n",
      "    X {\n",
      "        String standard_name \"longitude\";\n",
      "        Float32 pointwidth 0.5;\n",
      "        Int32 gridtype 1;\n",
      "        String units \"degree_east\";\n",
      "    }\n",
      "    T {\n",
      "        Float32 pointwidth 1.0;\n",
      "        String calendar \"360\";\n",
      "        Int32 gridtype 0;\n",
      "        String units \"months since 1960-01-01\";\n",
      "    }\n",
      "    Y {\n",
      "        String standard_name \"latitude\";\n",
      "        Float32 pointwidth 0.5;\n",
      "        Int32 gridtype 0;\n",
      "        String units \"degree_north\";\n",
      "    }\n",
      "    rain {\n",
      "        Int32 pointwidth 0;\n",
      "        String standard_name \"lwe_precipitation_rate\";\n",
      "        Float32 file_missing_value -999.0;\n",
      "        String history \"Boxes with less than 0.0% dropped\";\n",
      "        Float32 missing_value NaN;\n",
      "        String units \"mm/day\";\n",
      "        String long_name \"Monthly Precipitation\";\n",
      "    }\n",
      "NC_GLOBAL {\n",
      "    String Conventions \"IRIDL\";\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Get data attributes (5 points)\n",
    "# DAS (Dataset Attribute Structure) contains metadata\n",
    "das_url = base_url + \".das\"\n",
    "import requests\n",
    "\n",
    "das_url = base_url + \".das\"\n",
    "response = requests.get(das_url)\n",
    "\n",
    "print(\"Dataset Attributes:\")\n",
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b86eb-3ded-496c-8296-1f5546a0ebb6",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Document what you learned (5 points)\n",
    "# In a markdown cell, write:\n",
    "# - What does this dataset contain?\n",
    "# - What time period does it cover?\n",
    "# - What geographic region does it cover?\n",
    "# - What are the units of the main variable?\n",
    "# Find this info in the DAS output\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "- **What the dataset contains:** Monthly global precipitation estimates based on gauge observations.\n",
    "- **Time period covered:** A retrospective historical record spanning multiple decades.\n",1960-1986
    "- **Geographic region:** Global coverage on a latitude–longitude grid.\n",
    "- **Units of the main variable:** Millimeters (mm)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo23",
   "language": "python",
   "name": "pangeo23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
